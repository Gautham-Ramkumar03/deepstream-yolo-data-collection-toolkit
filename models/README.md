# Model Management Guide

## Follow All Instructions setup deepstream_demux.py and structured_saver.py before making the model

This directory contains the model files and conversion utilities for the DeepStream Data Collection Pipeline. This guide walks you through downloading, converting, and deploying YOLO models for use with DeepStream.

## üìÅ Directory Structure

```
models/
‚îú‚îÄ‚îÄ README.md                    # This guide
‚îú‚îÄ‚îÄ your-model.pt               # Original PyTorch model
‚îú‚îÄ‚îÄ your-model.pt.onnx          # ONNX converted model
‚îî‚îÄ‚îÄ your-model.pt.onnx_b*_gpu*_fp16.engine  # TensorRT engine (auto-generated)
```

## üöÄ Quick Start: YOLOv11m Example

### Step 1: Download YOLOv11m Model

```bash
# Navigate to models directory
cd models

# Download YOLOv11m detection model (22MB)
wget https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m.pt

# Verify download
ls -la yolo11m.pt
```

Alternative download methods:
```bash
# Using curl
curl -L -o yolo11m.pt https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m.pt

# Using Python (if wget/curl unavailable)
python3 -c "
from ultralytics import YOLO
model = YOLO('yolo11m.pt')  # Downloads automatically
"
```

### Step 2: Convert to ONNX

```bash
# Navigate to utils directory
cd ../utils

# Convert PyTorch model to ONNX
python3 export_yoloV8.py -w ../models/yolo11m.pt --opset 11 --dynamic

# Verify ONNX file creation
ls -la ../models/yolo11m.pt.onnx
```

### Step 3: Update DeepStream Configuration

Edit `scripts/ds_demux_pgie_config.txt`:

```ini
[property]
# Update path to your ONNX model 
onnx-file=../models/yolo11m.pt.onnx

# Comment out engine file for first run (will be auto-generated)
# model-engine-file=/home/user/path/to/deepstream-data-collection-pipeline/models/yolo11m.pt.onnx_b3_gpu0_fp16.engine

# YOLOv11m uses COCO dataset (80 classes)
num-detected-classes=80
```

### Step 4: First Run (Engine Generation)

```bash
cd ../scripts

# Run with your cameras - this will generate the TensorRT engine
python3 deepstream_demux.py -i /dev/video0

# Engine file will be automatically created:
# models/yolo11m.pt.onnx_b1_gpu0_fp16.engine (for single camera)
```

### Step 5: Update Config with Engine File

After successful first run, update `ds_demux_pgie_config.txt`:

```ini
[property]
onnx-file=/home/user/path/to/deepstream-data-collection-pipeline/models/yolo11m.pt.onnx
# Uncomment and update engine file path
model-engine-file=/home/user/path/to/deepstream-data-collection-pipeline/models/yolo11m.pt.onnx_b1_gpu0_fp16.engine
num-detected-classes=80
```

## üì• Available YOLO Models

### YOLOv11 Series (Recommended)
```bash
# YOLOv11 Nano (2.6MB) - Fastest
wget https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt

# YOLOv11 Small (9.7MB) - Balanced
wget https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s.pt

# YOLOv11 Medium (22MB) - Good accuracy
wget https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m.pt

# YOLOv11 Large (26MB) - High accuracy
wget https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11l.pt

# YOLOv11 Extra Large (58MB) - Highest accuracy
wget https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x.pt
```

### YOLOv8 Series (Legacy)
```bash
# YOLOv8 variants
wget https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt  # Nano
wget https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt  # Small
wget https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt  # Medium
wget https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l.pt  # Large
wget https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x.pt  # Extra Large
```

## üîÑ Model Conversion Process

### ONNX Conversion Options

The `export_yoloV8.py` utility supports various conversion options:

```bash
# Basic conversion
python3 export_yoloV8.py -w ../models/your-model.pt

# With specific ONNX opset version
python3 export_yoloV8.py -w ../models/your-model.pt --opset 11

# Dynamic batch size (recommended for multi-camera)
python3 export_yoloV8.py -w ../models/your-model.pt --dynamic

# Full options
python3 export_yoloV8.py -w ../models/your-model.pt --opset 11 --dynamic --simplify
```

### TensorRT Engine Generation

Engine files are automatically generated by DeepStream on first run. Key points:

- **Batch Size**: Determined by number of cameras in first run
- **Precision**: FP16 (default for Jetson), FP32 (dGPU)
- **GPU Specific**: Engine tied to specific GPU architecture
- **Reusable**: Once generated, subsequent runs are faster

### Engine Naming Convention
```
model-name.pt.onnx_b{BATCH}_gpu{GPU_ID}_{PRECISION}.engine

Examples:
yolo11m.pt.onnx_b1_gpu0_fp16.engine    # Single camera, GPU 0, FP16
yolo11m.pt.onnx_b3_gpu0_fp16.engine    # 3 cameras, GPU 0, FP16
yolo11m.pt.onnx_b5_gpu0_fp32.engine    # 5 cameras, GPU 0, FP32
```

## üéØ Custom Model Integration

### Using Your Own Trained Model

1. **Ensure Compatibility**:
   ```python
   # Your model should be YOLOv8/v11 format
   from ultralytics import YOLO
   model = YOLO('your-custom-model.pt')
   model.info()  # Check model details
   ```

2. **Convert to ONNX**:
   ```bash
   python3 export_yoloV8.py -w ../models/your-custom-model.pt --opset 11 --dynamic
   ```

3. **Update Class Configuration**:
   
   Edit `scripts/structured_saver_1.py`:
   ```python
   # Update with your custom classes
   CLASS_NAMES = {
       0: "your_class_1",
       1: "your_class_2",
       2: "your_class_3",
       # ... add all your classes
   }
   
   # Update class count
   NUM_CLASSES = len(CLASS_NAMES)
   ```

4. **Update DeepStream Config**:
   ```ini
   [property]
   onnx-file=/path/to/your-custom-model.pt.onnx
   num-detected-classes=YOUR_CLASS_COUNT
   ```

### Model Performance Comparison

| Model | Size | mAP50-95 | Speed (Jetson Orin) | Recommended Use |
|-------|------|----------|---------------------|-----------------|
| YOLOv11n | 2.6MB | 39.5 | ~60 FPS | Real-time, resource-constrained |
| YOLOv11s | 9.7MB | 47.0 | ~45 FPS | Balanced performance |
| YOLOv11m | 22MB | 51.5 | ~30 FPS | Good accuracy, moderate speed |
| YOLOv11l | 26MB | 53.4 | ~25 FPS | High accuracy applications |
| YOLOv11x | 58MB | 54.7 | ~15 FPS | Maximum accuracy |

## üîß Troubleshooting

### Common Issues

**ONNX Conversion Fails**:
```bash
# Install required dependencies
pip install ultralytics torch torchvision onnx onnxsim

# Try with different opset version
python3 export_yoloV8.py -w ../models/your-model.pt --opset 12
```

**Engine Generation Fails**:
- Ensure ONNX file path is absolute in config
- Check GPU memory availability
- Verify DeepStream version compatibility

**Model Not Loading**:
```bash
# Check model file integrity
python3 -c "
from ultralytics import YOLO
model = YOLO('../models/your-model.pt')
print(f'Classes: {model.names}')
print(f'Model type: {model.task}')
"
```

**Performance Issues**:
- Use smaller model variants for real-time processing
- Enable FP16 precision on compatible hardware
- Optimize batch size based on available GPU memory

### Validation Commands

```bash
# Verify ONNX model
python3 -c "
import onnx
model = onnx.load('../models/your-model.pt.onnx')
onnx.checker.check_model(model)
print('ONNX model is valid')
"

# Check TensorRT engine info
ls -la ../models/*.engine
```

## üìä Model Selection Guide

### For Jetson Nano (4GB)
- **Recommended**: YOLOv11n, YOLOv11s
- **Max Cameras**: 1-2
- **Batch Size**: 1

### For Jetson Xavier NX (8GB)
- **Recommended**: YOLOv11s, YOLOv11m
- **Max Cameras**: 2-4
- **Batch Size**: 2-4

### For Jetson Orin (32GB)
- **Recommended**: YOLOv11m, YOLOv11l
- **Max Cameras**: 4-8
- **Batch Size**: 4-8

### For dGPU Systems
- **Recommended**: Any model based on requirements
- **Max Cameras**: Limited by GPU memory
- **Batch Size**: Optimize based on GPU specs

## üîÑ Model Updates

To update to a newer model:

1. Download new model to `models/` directory
2. Convert to ONNX using export utility
3. Update configuration file paths
4. Remove old engine files (will regenerate automatically)
5. Run pipeline to generate new engine

```bash
# Clean old engines
rm models/*.engine

# Update config and run
python3 deepstream_demux.py -i /dev/video0
```

## üìö Additional Resources

- [Ultralytics YOLOv11 Documentation](https://docs.ultralytics.com/models/yolo11/)
- [NVIDIA DeepStream SDK Guide](https://docs.nvidia.com/metropolis/deepstream/dev-guide/)
- [TensorRT Developer Guide](https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/)
- [ONNX Model Zoo](https://github.com/onnx/models)